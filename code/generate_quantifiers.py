#!/usr/bin/python3.7

import argparse
import itertools as it
import pickle
import re
from functools import lru_cache
from time import perf_counter

from bitarray import bitarray
from nltk import CFG
from nltk.parse.generate import generate as nltk_generate


class QuantifierGenerator:
    STRING_CACHE_SIZE = 1024
    A_AND_B = 0
    A_NOT_B = 1
    B_NOT_A = 2

    def __init__(self, grammar, upper, max_depth, verbose):
        self.start_t = perf_counter()
        self.grammar = grammar
        self.upper = upper
        self.max_depth = max_depth
        self.verbose = verbose

    @lru_cache(maxsize=None)
    def build_lists(model):
        """
        Given a ternary string representing a model (i.e. one in which
        the values at each index represent the 'zone' of the model the object
        for that index is in), build explicit lists for the A and B zones of
        the model.

        Parameters
        ----------
        model : array-like[int]
            Ternary strings representing the model.

        Returns
        -------
        tuple[list[int], list[int]]
            The A and B lists in the model.
        """
        a = []
        b = []

        for i, zone in enumerate(model):
            if zone == QuantifierGenerator.A_AND_B:
                a.append(i)
                b.append(i)
            elif zone == QuantifierGenerator.A_NOT_B:
                a.append(i)
            elif zone == QuantifierGenerator.B_NOT_A:
                b.append(i)

        return a, b

    def build_q_str(self, q):
        """
        Given a function q representing a generalised quantifier, build the
        quantifier's binary representation.

        Parameters
        ----------
        q : list[int], list[int] -> bool
            The evaluation function of the generalised quantifier.

        Returns
        -------
        bitarray
            The binary string generated by evaluating the quantifier on each of
            the models within the given bounds.
        """
        # Since models correspond to ternary strings, the number of models of
        # size s is 3^s.
        q_str_len = sum([3 ** model_size
                         for model_size in range(1, self.upper + 1)])

        # Work with bitarrays for efficiency
        q_str = bitarray(q_str_len)

        # Index pointing to the beginning of the part of the string
        # corresponding to a fixed model size.
        base_idx = 0

        for model_size in range(1, self.upper + 1):
            for i, model in enumerate(it.product(range(3), repeat=model_size)):
                # Evaluate quantifier on the model
                q_str[base_idx +
                      i] = q(*QuantifierGenerator.build_lists(model))

            base_idx += 3 ** model_size

        return q_str

    def generate(self):
        """
        Generator producing semantically distinct quantifier expressions along
        with their binary representations.

        Yields
        -------
        string, bitarray
            The expression and the binary string.
        """
        # Set used to skip over semantically equivalent quantifiers
        q_str_set = set()

        i = 1

        for depth in range(1, self.max_depth + 1):
            if self.verbose:
                print(f'Now searching grammar at depth {depth}')
            for expr_list in nltk_generate(self.grammar, depth=depth):
                # expr_list consists of each symbol in the production
                expr = ''.join(expr_list)

                # Evaluate the function written in the expression
                q = eval(expr)

                # Build quantifier string
                q_str = self.build_q_str(q)

                # Check if we have already had a semantically equivalent
                # quantifier by keeping track of binary strings
                q_str_hash = q_str.tobytes()
                if q_str_hash not in q_str_set:
                    q_str_set.add(q_str_hash)
                    if self.verbose:
                        print(f'Building string #{i} done after'
                              f' {(perf_counter() - self.start_t):.4f} s')
                    i += 1
                    yield expr, q_str


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('-u', '--upper', type=int, required=True,
                        help='Model size upper bound')
    parser.add_argument('-d', '--depth', type=int, required=True,
                        help='Maximum CFG production depth considered')
    parser.add_argument('-v', '--verbose', action='store_true',
                        help='Show progress and timing')
    parser.add_argument('-i', '--input', type=str, required=True,
                        help='Path to text file containing CFG specification')
    parser.add_argument('-e', '--expr', type=str, required=True,
                        help='Path quantifier expressions should'
                        ' be saved in')
    parser.add_argument('-b', '--bit', type=str, required=True,
                        help='Path quantifier bitstrings should be saved in')

    args = parser.parse_args()

    upper = args.upper
    max_depth = args.depth
    verbose = args.verbose
    in_file = args.input
    expr_file = args.expr
    bit_file = args.bit

    with open(in_file, 'r') as f:
        grammar_str = f.read()

        # NLTK does not like unnecessary indentation
        pattern = re.compile(r'\n\s+\|')
        grammar_str = pattern.sub(' |', grammar_str)
        grammar = CFG.fromstring(grammar_str)

    qg = QuantifierGenerator(grammar, upper, max_depth, verbose)

    with open(expr_file, 'w') as f_expr:
        with open(bit_file, 'wb') as f_bit:
            for expr, q_str in qg.generate():
                f_expr.write(f'{expr}\n')
                f_bit.write(q_str.tobytes())


if __name__ == '__main__':
    main()
